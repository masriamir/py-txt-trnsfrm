name: CI/CD Pipeline

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main
  workflow_dispatch:
    inputs:
      debug_enabled:
        description: 'Enable debugging with tmate'
        required: false
        default: false
        type: boolean

env:
  PYTHON_VERSION: "3.13"
  UV_VERSION: ">=0.8.11,<0.9.0"
  PYTHONPATH: ${{ github.workspace }}
  FLASK_ENV: production

jobs:
  lint:
    name: Code Quality & Linting
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v5
      with:
        show-progress: true

    - name: Install uv
      uses: astral-sh/setup-uv@v6
      with:
        enable-cache: true
        version: ${{ env.UV_VERSION }}

    - name: Install Python ${{ env.PYTHON_VERSION }}
      run: uv python install ${{ env.PYTHON_VERSION }}

    - name: Cache uv dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/uv
          .venv
        key: uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('uv.lock', 'pyproject.toml') }}
        restore-keys: |
          uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-

    - name: Install dependencies
      run: uv sync --group dev --group test --group security

    - name: Run ruff linting
      run: |
        echo "::group::Ruff Check"
        uv run ruff check . --output-format=github
        echo "::endgroup::"

    - name: Run ruff formatting check
      run: |
        echo "::group::Ruff Format Check"
        uv run ruff format --check .
        echo "::endgroup::"

    - name: Run black formatting check
      run: |
        echo "::group::Black Format Check"
        uv run black --check --diff .
        echo "::endgroup::"

    - name: Run mypy type checking
      run: |
        echo "::group::MyPy Type Checking"
        uv run mypy app/ --show-error-codes --show-error-context
        echo "::endgroup::"

  test:
    name: Tests (${{ matrix.test-type }})
    runs-on: ubuntu-latest
    timeout-minutes: 20
    
    strategy:
      fail-fast: false
      matrix:
        test-type: [unit, integration, api, smoke, network]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v5
      with:
        show-progress: true

    - name: Install uv
      uses: astral-sh/setup-uv@v6
      with:
        enable-cache: true
        version: ${{ env.UV_VERSION }}

    - name: Install Python ${{ env.PYTHON_VERSION }}
      run: uv python install ${{ env.PYTHON_VERSION }}

    - name: Cache uv dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/uv
          .venv
        key: uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('uv.lock', 'pyproject.toml') }}
        restore-keys: |
          uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-

    - name: Install dependencies
      run: uv sync --group dev --group test --group security

    - name: Create reports directory
      run: mkdir -p reports/coverage

    - name: Run ${{ matrix.test-type }} tests
      run: |
        uv run pytest \
          -m ${{ matrix.test-type }} \
          --tb=short \
          --cov=app \
          --cov-report=xml:reports/coverage/coverage-${{ matrix.test-type }}.xml \
          --cov-report=html:reports/coverage/html-${{ matrix.test-type }} \
          --cov-report=term \
          --junitxml=reports/pytest-${{ matrix.test-type }}.xml \
          --durations=10 \
          --maxfail=5
      env:
        FLASK_ENV: testing

    - name: Upload coverage reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: coverage-${{ matrix.test-type }}
        path: |
          reports/coverage/coverage-${{ matrix.test-type }}.xml
          reports/coverage/html-${{ matrix.test-type }}/
        retention-days: 30

    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ matrix.test-type }}
        path: reports/pytest-${{ matrix.test-type }}.xml
        retention-days: 30

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v5
      if: success()
      with:
        files: ./reports/coverage/coverage-${{ matrix.test-type }}.xml
        flags: ${{ matrix.test-type }}
        name: codecov-${{ matrix.test-type }}
        fail_ci_if_error: false
        token: ${{ secrets.CODECOV_TOKEN }}

  test-slow:
    name: Slow Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    if: github.event_name != 'pull_request' || contains(github.event.pull_request.labels.*.name, 'run-slow-tests')
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v5
      with:
        show-progress: true

    - name: Install uv
      uses: astral-sh/setup-uv@v6
      with:
        enable-cache: true
        version: ${{ env.UV_VERSION }}

    - name: Install Python ${{ env.PYTHON_VERSION }}
      run: uv python install ${{ env.PYTHON_VERSION }}

    - name: Cache uv dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/uv
          .venv
        key: uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('uv.lock', 'pyproject.toml') }}
        restore-keys: |
          uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-

    - name: Install dependencies
      run: uv sync --group dev --group test --group security

    - name: Create reports directory
      run: mkdir -p reports/coverage

    - name: Run slow tests
      run: |
        uv run pytest \
          -m slow \
          --tb=short \
          --cov=app \
          --cov-report=xml:reports/coverage/coverage-slow.xml \
          --cov-report=html:reports/coverage/html-slow \
          --cov-report=term \
          --junitxml=reports/pytest-slow.xml \
          --durations=10 \
          --maxfail=3 \
          --timeout=900
      env:
        FLASK_ENV: testing

    - name: Upload slow test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-slow
        path: |
          reports/coverage/coverage-slow.xml
          reports/coverage/html-slow/
          reports/pytest-slow.xml
        retention-days: 30

  security:
    name: Security Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v5
      with:
        show-progress: true

    - name: Install uv
      uses: astral-sh/setup-uv@v6
      with:
        enable-cache: true
        version: ${{ env.UV_VERSION }}

    - name: Install Python ${{ env.PYTHON_VERSION }}
      run: uv python install ${{ env.PYTHON_VERSION }}

    - name: Cache uv dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.cache/uv
          .venv
        key: uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('uv.lock', 'pyproject.toml') }}
        restore-keys: |
          uv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-

    - name: Install dependencies
      run: uv sync --group dev --group test --group security

    - name: Install system dependencies for security tools
      run: |
        sudo apt-get update && sudo apt-get install -y jq

    - name: Create reports directory
      run: mkdir -p reports/security

    - name: Run security analysis
      run: |
        chmod +x ./run_security_analysis.sh
        ./run_security_analysis.sh
      env:
        # Allow safety to work without authentication for basic scans
        SAFETY_DB_CACHE_PATH: /tmp/safety-cache

    - name: Security report summary
      if: always()
      run: |
        echo "## Security Analysis Summary" >> $GITHUB_STEP_SUMMARY
        if [ -f "reports/security/security_summary.txt" ]; then
          echo "### Quick Summary" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          cat reports/security/security_summary.txt >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ -f "reports/security/bandit_report.json" ]; then
          HIGH_ISSUES=$(jq '.results | map(select(.issue_confidence == "HIGH")) | length' reports/security/bandit_report.json 2>/dev/null || echo "0")
          echo "**Bandit High Confidence Issues:** $HIGH_ISSUES" >> $GITHUB_STEP_SUMMARY
        fi

    - name: Upload security reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-reports
        path: |
          reports/security/
        retention-days: 90

    - name: Check for high-severity security issues
      run: |
        if [ -f "reports/security/bandit_report.json" ]; then
          HIGH_ISSUES=$(jq '.results | map(select(.issue_confidence == "HIGH")) | length' reports/security/bandit_report.json 2>/dev/null || echo "0")
          if [ "$HIGH_ISSUES" -gt 0 ]; then
            echo "::warning::Found $HIGH_ISSUES high-confidence security issues. Please review the security reports."
          fi
        fi

  build:
    name: Docker Build & Validation
    runs-on: ubuntu-latest
    needs: [lint, test, security]
    timeout-minutes: 20
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v5
      with:
        show-progress: true

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Cache Docker layers
      uses: actions/cache@v4
      with:
        path: /tmp/.buildx-cache
        key: ${{ runner.os }}-buildx-${{ github.sha }}
        restore-keys: |
          ${{ runner.os }}-buildx-

    - name: Build Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        file: ./Dockerfile
        push: false
        tags: py-txt-trnsfrm:latest
        cache-from: type=local,src=/tmp/.buildx-cache
        cache-to: type=local,dest=/tmp/.buildx-cache-new,mode=max
        outputs: type=docker,dest=/tmp/py-txt-trnsfrm.tar

    - name: Load Docker image
      run: docker load --input /tmp/py-txt-trnsfrm.tar

    - name: Test Docker container startup
      run: |
        # Start container in background
        docker run -d --name test-container -p 5000:5000 \
          -e FLASK_ENV=production \
          -e PORT=5000 \
          py-txt-trnsfrm:latest
        
        # Wait for container to be ready
        sleep 10
        
        # Check if container is running
        if ! docker ps | grep test-container; then
          echo "Container failed to start"
          docker logs test-container
          exit 1
        fi

    - name: Test health endpoint
      run: |
        # Wait for application to be ready
        for i in {1..30}; do
          if curl -f http://localhost:5000/health; then
            echo "Health check passed!"
            break
          fi
          echo "Waiting for application... ($i/30)"
          sleep 2
        done
        
        # Final health check
        curl -f http://localhost:5000/health || {
          echo "Health check failed"
          docker logs test-container
          exit 1
        }

    - name: Test basic functionality
      run: |
        # Test main page
        curl -f http://localhost:5000/ > /dev/null || {
          echo "Main page test failed"
          docker logs test-container
          exit 1
        }
        
        # Test API endpoint with sample data (using l33t_speak transformation)
        response=$(curl -s -X POST http://localhost:5000/transform \
          -H "Content-Type: application/json" \
          -d '{"text": "test", "transformation": "l33t_speak"}')
        
        if echo "$response" | jq -e '.success' > /dev/null; then
          echo "API functionality test passed!"
          echo "Response: $response"
        else
          echo "API functionality test failed: $response"
          docker logs test-container
          exit 1
        fi

    - name: Stop and cleanup container
      if: always()
      run: |
        docker stop test-container || true
        docker rm test-container || true

    - name: Move Docker cache
      if: always()
      run: |
        rm -rf /tmp/.buildx-cache
        mv /tmp/.buildx-cache-new /tmp/.buildx-cache || true

    - name: Upload Docker build logs
      uses: actions/upload-artifact@v4
      if: failure()
      with:
        name: docker-logs
        path: /tmp/docker-build.log
        retention-days: 7

  coverage-summary:
    name: Coverage Summary
    runs-on: ubuntu-latest
    needs: [test]
    if: always() && needs.test.result != 'cancelled'
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v5

    - name: Download all coverage reports
      uses: actions/download-artifact@v4
      with:
        pattern: coverage-*
        merge-multiple: true
        path: coverage-reports

    - name: Install tools for coverage processing
      run: |
        python -m pip install coverage[toml]

    - name: List coverage files
      run: |
        find coverage-reports -name "*.xml" -o -name "*.coverage" || true
        ls -la coverage-reports/ || true

    - name: Process coverage reports
      run: |
        echo "## Test Coverage Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Count coverage reports
        COVERAGE_FILES=$(find coverage-reports -name "coverage-*.xml" | wc -l)
        echo "Found $COVERAGE_FILES coverage reports" >> $GITHUB_STEP_SUMMARY
        
        if [ "$COVERAGE_FILES" -gt 0 ]; then
          echo "### Coverage Reports Generated" >> $GITHUB_STEP_SUMMARY
          echo "| Test Type | Report Available |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|------------------|" >> $GITHUB_STEP_SUMMARY
          
          for file in coverage-reports/coverage-*.xml; do
            if [ -f "$file" ]; then
              test_type=$(basename "$file" | sed 's/coverage-//; s/.xml//')
              echo "| $test_type | ✅ |" >> $GITHUB_STEP_SUMMARY
            fi
          done
        else
          echo "No coverage reports found" >> $GITHUB_STEP_SUMMARY
        fi

    - name: Upload combined coverage
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: coverage-summary
        path: coverage-reports/
        retention-days: 30

  status-check:
    name: Status Check
    runs-on: ubuntu-latest
    needs: [lint, test, security, build]
    if: always()
    
    steps:
    - name: Check overall status
      run: |
        echo "## CI/CD Pipeline Results" >> $GITHUB_STEP_SUMMARY
        echo "| Job | Status |" >> $GITHUB_STEP_SUMMARY
        echo "|-----|--------|" >> $GITHUB_STEP_SUMMARY
        echo "| Lint | ${{ needs.lint.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Tests | ${{ needs.test.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Security | ${{ needs.security.result }} |" >> $GITHUB_STEP_SUMMARY
        echo "| Build | ${{ needs.build.result }} |" >> $GITHUB_STEP_SUMMARY
        
        # Check if any critical jobs failed
        if [[ "${{ needs.lint.result }}" == "failure" || "${{ needs.test.result }}" == "failure" || "${{ needs.build.result }}" == "failure" ]]; then
          echo "::error::Critical CI jobs failed"
          exit 1
        fi
        
        # Warning for security issues but don't fail
        if [[ "${{ needs.security.result }}" == "failure" ]]; then
          echo "::warning::Security analysis had issues, please review"
        fi
        
        echo "✅ CI/CD Pipeline completed successfully!"